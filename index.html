<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Haoquan Zhang 张皓泉</title>
    <meta name="author" content="HaoquanZhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/whale.png" type="image/x-icon">

    <link rel="stylesheet" href="desktop.css" media="screen and (min-width: 601px)">
    <link rel="stylesheet" href="mobile.css" media="screen and (max-width: 600px)">
  </head>

  <body >
    <div class="mobile-component">
      <ul>
        <li><a href="#Top"><strong>Haoquan Zhang</strong></a></li>&nbsp;·&nbsp;
        <li><a href="#ResearchExperience">🔬</a></li>&nbsp;·&nbsp;
        <!-- <li><a href="#Education">📚</a></li>&nbsp;·&nbsp; -->
        <li><a href="#Research">💡</a></li>&nbsp;·&nbsp;
        <li><a href="#Projects">📂</a></li>&nbsp;·&nbsp;
        <li><a href="#Awards">🏆</a></li>
      </ul>
    </div>

    <div class="desktop-component">
      <ul>
        <li><a href="#Top" style="font-size: x-large;"><strong>Haoquan Zhang</strong></a></li>&nbsp;·&nbsp;
        <li><a href="#ResearchExperience">Experience</a></li>&nbsp;·&nbsp;
        <!-- <li><a href="#Education">Education</a></li>&nbsp;·&nbsp; -->
        <li><a href="#Research">Research</a></li>&nbsp;·&nbsp;
        <li><a href="#Projects">Projects</a></li>&nbsp;·&nbsp;
        <li><a href="#Awards">Awards</a></li>
      </ul>
    </div>

    <script>
      // Get the height of the mobile and desktop navigation bars
      var navbarHeightMobile = document.querySelector('.mobile-component ul').offsetHeight;
      var navbarHeightDesktop = document.querySelector('.desktop-component ul').offsetHeight;
  
      // Add click event listeners to navigation links
      document.querySelectorAll('.mobile-component ul li a, .desktop-component ul li a, .a').forEach(function(anchor) {
          anchor.addEventListener('click', function(event) {
              event.preventDefault(); // Prevent the default navigation behavior
  
              var targetId = this.getAttribute('href'); // Get the target section's ID from the link's href
              var targetElement = document.querySelector(targetId); // Find the target element using its ID
              var targetOffsetTop = targetElement.offsetTop; // Get the target's top offset relative to the document
  
              // Calculate scroll position considering the navigation bar height to avoid overlap
              var navbarHeight = (window.innerWidth < 768) ? navbarHeightMobile : navbarHeightDesktop;
              window.scrollTo({
                  top: targetOffsetTop - navbarHeight,
                  behavior: 'smooth' // Smooth scroll to the target position
              });
          });
      });
    </script>

    <section id="Top"></section>
    <table style="max-width:900px;margin:auto;padding-top: 30px;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px"> 
          <div class="bio" >
            <div class="face-name">
              <img src="images/thewoman.jpg" alt="profile photo" class="profile-img">
              <div class="name-info">
                  张皓泉 <br> 
                  Haoquan Zhang
              </div>
            </div>
            <br>
            <p>
              Hi, my name is Haoquan Zhang, a junior undergraduate majoring in Data Science at South China University of Technology (SCUT). I am currently working with <a href="https://wyliu.com/">Prof. Weiyang Liu</a>, focusing on Generative synthesis and Large Language Models. Additionally, I am collaborating with <a href="http://www.shengfenghe.com/">Prof. Shengfeng He @SMU</a> to address challenges in Knowledge Distillation. I also have experience in Biomedical Signal Processing.
            </p>
            <p>
              <strong>My ideal is to follow my interests and create simple yet enjoyable work! 🌟</strong>
            </p>
            <p>
              <strong style="color: rgb(255, 67, 183);">I’m currently seeking a PhD position for Fall 2025 admission.</strong>
            </p>
            <div class="links">
              <a href="data/resume.pdf">CV</a> &nbsp;·&nbsp;
              <!-- <a href="data/resume-zh.pdf">CV-zh</a> &nbsp;·&nbsp; -->
              <a href="https://www.zhihu.com/people/homybush">Zhihu</a> &nbsp;·&nbsp;
              <a href="https://github.com/HaoquanZhang">Github</a> &nbsp;·&nbsp;
              <a href="https://scholar.google.com/citations?user=gADoQmcAAAAJ&amp;hl=en">Google Scholar</a> &nbsp;·&nbsp;
              <a href="mailto:haoquanzhang@outlook.com">Email</a>
            </div>
          </div>
          

          <hr>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2><strong>News📰</strong></h2>
                </td>
              </tr>
            </tbody>
          </table>
  
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:85%;vertical-align:middle">

                  <p style="color: rgb(59, 59, 59);font-size: larger;">
                    <strong>[2024/6/14]</strong> - Mask4Align now released!
                  </p>
                  <p style="color: rgb(59, 59, 59);font-size: larger;">
                    <strong>[2024/2/27]</strong> - My first paper accepted by CVPR 2024! See you in Seattle! 
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        
        <hr>
        <section id="ResearchExperience"></section>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <h2><strong>Experience 🔬</strong></h2>
          </td>
          </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100px;vertical-align:middle">
                <img src="images/smu.svg" alt="Your Image Alt Text" style="width: 100%; height: auto;">
              </td>
        
              <td style="padding:20px;width:auto;vertical-align:middle">
                <p><strong style="font-size: larger;">Singapore Managment University</strong>
                  <br>
                  <em>Research Intern</em>
                  <br>

                  <br>
                  3D Reconstruction, Knowledge Distillation
                  <br>
                  advised by <a href="http://www.shengfenghe.com/">Prof. Shengfeng He</a>
                  </p>

                  <p> 
                    Singapore. 2024/2 - present
                  </p>

              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;width:100px;vertical-align:middle">
                <img src="images/scut_logo.png" alt="Your Image Alt Text" style="width: 100%; height: auto;">
              </td>
        
              <td style="padding:20px;width:auto;vertical-align:middle">
                <p><strong style="font-size: larger;">South China University of Technology</strong>
                  <br>
                  <em>Research Intern</em>
                  <br>
                  <br>
                  Application of Vision Language Model, 
                  <br>
                  advised by <a href="https://scholar.google.com/citations?user=cC_WhWkAAAAJ">Prof. Huaidong Zhang</a>
                </p>
                  <p>
                    Guangzhou, China. 2023/8 - 2024/2
                  </p>
              </td>
            </tr>
          </tbody>
        </table>

        <hr>
        <section id="Research"></section>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2><strong>Research 💡</strong></h2>
              
              <br>
              <h2 style="font-size:large;"><strong>Interests:</strong></h2>
              <br>
              <div class="interest">
                · <em><strong>Multi-Modality Representation Learning</strong></em> 🔄
              </div>
              <br>
              <div class="interest">
                · <em><strong>Knowledge Distillation</strong></em> 💧
              </div>
              <br>
              <!-- <div class="interest">
                · <em><strong>3D Reconstruction</strong></em> 🧊
              </div>
              <br> -->
              <div class="interest">
                · <em><strong>Interactive Generation</strong></em> 👋
              </div>
            
            
              
            </td>
          </tr>
        </tbody></table>

        <section id="Mask4Align"></section>

          <div class="paper-container">
            <div class="image">
              <img src='images/M4A.png' alt="Mask4Align">
            </div>
            <div class="text">
              <span class="papertitle">Mask4Align: Aligned Entity Prompting with Color Masks for Multi-Entity Localization Problems</span><br>
              
              <p>
                <strong>Haoquan Zhang</strong>,
                Ronggang Huang,
                Yi Xie,
                <a href="https://scholar.google.com/citations?user=cC_WhWkAAAAJ">Huaidong Zhang</a>
              </p>
        
              <p>
                Pretrained VLMs excel in accurately recognizing and precisely localizing entities within VQA tasks. However, in visual scenes with multiple entities, textual descriptions struggle to distinguish the entities from the same category effectively. Consequently, the existing VQA dataset cannot adequately cover scenarios involving multiple entities. Therefore, we introduce a Mask for Align (Mask4Align) method to determine the entity's position in the given image that best matches the user input question. This method incorporates colored masks into the image, enabling the VQA model to handle discrimination and localization challenges associated with multiple entities.
              </p>
        
              <p>
                <strong class="buttom"><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Mask4Align_Aligned_Entity_Prompting_with_Color_Masks_for_Multi-Entity_Localization_CVPR_2024_paper.pdf">[Paper]</a></strong>
                <strong class="buttom"><a href="https://github.com/HaoquanZhang/mask4align">[Code]</a></strong>
                <strong class="buttom"><a href="https://www.zhihu.com/question/627841035/answer/3286130863">[Submission Journey]</a></strong>  
              </p>
        
              <div class="CVPR">
                <strong>CVPR 2024</strong>
              </div>
            </div>
          </div>

          <div class="paper-container">
            <div class="image">
              <img src='images/SCD-2024.png' alt="Mask4Align">
            </div>
            <div class="text">
              <span class="papertitle">Asymmetric Image Retrieval with Semi-Collaborative Distillation</span><br>
              
              <p>
                Yi Xie*,
                <strong>Haoquan Zhang*</strong>,
                Xuandi Luo,
                Huaidong Zhang,
                Xuemiao Xu,
                <a href="http://www.shengfenghe.com/">Shengfeng He</a>
                <br>
                <em style="color: rgb(160, 160, 160);font-size: smaller;">* Co-first authorship</em>
              </p>
        
              <p>
                In asymmetric image retrieval systems, there is a significant capacity gap between the query and gallery network. The low-capacity query network struggles to effectively store and understand knowledge from the high-capacity teacher network. Therefore, we introduce a simple yet effective semi-collaborative distillation (SCD) framework, which can additionally adjust the gallery network because the gallery network has a redundant capacity to carry specific knowledge from the query network. Specifically, as the query network converges, we incrementally unfreeze the gallery network to smoothly adjust the feature space of the gallery network to be consistent with that of the query network.
              </p>
        
              <p>
                <strong class="buttom">[Paper]</strong>
                <strong class="buttom">[Code]</strong> 
              </p>
        
              <div class="insub">
                <strong>Under Review</strong>
              </div>
            </div>
          </div>

          <hr>
          <section id="Projects"></section>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2><strong>Projects 📂</strong></h2>
            </td>
            </tr>
            </tbody>
          </table>

          <div class="paper-container">
            <div class="image">
              <img src='images/BEM2023CONTEST.png' alt="BEM 2023 Contest" >
            </div>
            <div class="text">
              <span class="papertitle">Design of Auxiliary Diagnosis Algorithm for Schizophrenia Based on Feature Fusion of EEG and ECG</span><br>
              <strong><a href="NBMEC_2023/B030079.pdf">[Entry (Chinese)]</a></strong>
              <p></p>
              <em>Entry</em>, 2023, National Biomedical Engineering Innovation Design Competition for College Students
              <br>
              <p></p>
              <p>
                Calculated brain functional network features, heart rate variability features and heart-brain coupling features to build machine learning models for automatic diagnosis; Deep learning models using ResNet were built based on original EEG and ECG also.
              </p>
              <p><strong>Second Prize. (6%)</strong></p>
              <p style="color: rgb(160, 160, 160);font-size: smaller;">
                This work has been further developed by a team member and has been submitted to the IEEE Transactions on Neural Systems & Rehabilitation Engineering for review.
              </p>
            </div>
          </div>

          <div class="paper-container" >
            <div class="image" onmouseout="gun_stop()" onmouseover="gun_start()">
              <img src='images/gunmayhem_logo.png'>
            </div>
            <div class="text">
              <span class="papertitle">Perfect GunMayhem Remake: A 2D Shooting PVP Game Based on Cocos2d-x</span><br>
              <strong><a href="https://github.com/Randonee1/Advanced-Language-Programming">[Github]</a></strong> · 
              <strong><a href="GunMayhem/gunMayhem.html">[Project Page]</a></strong> · 
              <strong><a href="https://gun-mayhem-2.github.io/">[Original Game]</a></strong> · 
              <strong><a href="/GunMayhem/gunmayhem_GameArts.zip">[Art Assets (.ai)]</a></strong>
              <br><br>
              <em>Course design</em>, 2022, Advanced Language Programming (C++)
              <br>
              <p> 
                GunMayhem Remake is a project independently completed by our team members, covering all aspects, including source code, game artwork, and music assets. You can play our <a href="https://github.com/Randonee1/Advanced-Language-Programming/tree/main/dist">executable file</a>.
              </p>
              <p>
                <span style="color: rgb(182, 48, 240);">Shoutout to <a href="https://www.thekevingu.com/">Kevin Gu</a> for creating this incredible game!</span>
              </p>
              <p><strong>Final Score: 99, 4.0/4.0. (1%)</strong></p>
            </div>
          </div>

          <div class="paper-container">
            <div class="image">
              <img src='images/eeg-monitor.png' alt="EEG Monitor">
            </div>
            <div class="text">
              <span class="papertitle">Limbs Motor Function Monitoring System Based on EEG and EMG Detection and Analysis</span><br>
              <strong><a href="LimbMonitor/Poster.pdf">[Poster]</a></strong> · 
              <strong><a href="LimbMonitor/bme-2022-intro.pptx">[Poster Source File (.pptx)]</a></strong>
              <br><br>
              <em>Course design</em>, 2021, Exploration and Design of Biomedical Engineering
              <br>
              <p>
                Built an automatic classification system to assess the subject’s weight-bearing status based on EEG and EMG. This design is an exploration of the ability of EEG and EMG to assess the motor status of stroke patients.
              </p>
              <p><strong>Final Score: 92, 4.0/4.0.</strong></p>
            </div>
          </div>

          <hr>
          <section id="Awards"></section>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2><strong>Awards 🏆</strong></h2>

                <p><strong>TaiHu Innovation Prize (1%)</strong>,
                <br>Highest scholarship, which awarded by the Wuxi governments, 2024</p>
                
                <p><strong>Second Prize (6%)</strong>,
                <br>The National BME lnnovation Design Competition, China Society of Biomedical Engineering, 2023</p>

                <!-- <p><strong>Second Prize (5%)</strong>, 
                <br>The Taihu Innovation Scholarship, Wuxi city government, 2022</p>

                <p><strong>Third Prize (12%)</strong>, 
                <br>The SCUT Scholarship, SCUT, 2022</p>

                <p><strong>Third Prize (12%)</strong>, 
                <br>The Huameng Scholarships, TCL Corporate , 2022</p> -->

                <p><strong>Meritorious Winner (6%)</strong>, 
                <br>The Interdisciplinary Contest in Modeling (ICM), <a href="https://www.comap.com/">COMAP</a>, 2021</p>
  
              </td>
            </tr>
          </tbody></table>
          
          <hr>
          <section id="Friends"></section>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
                <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                <h2><strong>Friends 🤜🤛</strong></h2>
                  <br>
                <div class="image-text-container">
                  <div class="image">
                      <img src="images/scut_logo.png">
                  </div>

                  <div class="text">
                  <table>
                    <tr>
                        <td><strong><a href="https://tobyleelsz.github.io/">Shangzhe Li</a></strong></td>
                        <td>Research Intern @UCSD</td>
                        <td><em>Reinforcement Learning · physics enthusiast · pilot</em></td>
                    </tr>
                    <tr>
                        <td><strong><a href="https://xinjie-shen.com/">Xinjie Shen</a></strong></td>
                        <td>Research Intern @Dartmouth</td>
                        <td><em>Interaction · Graph · Quantitative Finance</em></td>
                    </tr>
                    <tr>
                        <td><strong><a href="https://brandon-liu-jx.github.io/">Jinxiu Liu</a></strong></td>
                        <td>Research Intern @Stanford</td>
                        <td><em>4D Dynamic Generation · MLLM</em></td>
                    </tr>
                    <tr>
                        <td><strong><a href="https://troychowzyb.github.io/">Yubin Zhou</a></strong></td>
                        <td>Research Intern @BrainCo</td>
                        <td><em>Brain-Computer Interface · Cognitive Neuroscience</em></td>
                    </tr>
                  </table>
                </div>
                
                </div>

                <div class="image-text-container">
                  <div class="image">
                      <img src="images/NYU.jpg">
                  </div>
                  <div class="text">
                    <table>
                      <tr>
                        <td><strong>Junru Liao</strong></td>
                        <td>Undergraduate @NYU</td>
                        <td><em>Biomechanics · Cellular Mechanics Response</em></td>
                      </tr>
                    </table>
                  </div>
                </div>

                <!-- <div class="image-text-container">
                  <div class="image">
                      <img src="images/Sun_Yat-sen_University_Logo.png">
                  </div>
                  <div class="text">
                    <h2 style="padding-bottom:10px;">Sun Yat-sen University</h2>

                    <strong>HONG Xuan</strong>
                     - <em>High-Energy Phenomenology · Particle Physics · Cosmology<br>

                    <strong>FAN Wei</strong>
                     - <em>Piezoelectricity · Semiconductor · DeviceFabrication<br>
                  </div>
                </div> -->

                </td>
            </tr>
            </tbody>
          </table>
          
          <hr>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;">
                    Thanks to <a href="https://github.com/jonbarron/jonbarron_website">John Barron</a> for this homepage template.
                    <br>
                    Feel free to take the <a href="https://github.com/HaoquanZhang/HaoquanZhang.github.io">resources</a> of this page.
                  </p>
                  <p style="text-align:center;color: rgb(143, 143, 143);">
                    © 2024 Haoquan Zhang
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

        </td>
      </tr>
    </table>
  </body>
</html>